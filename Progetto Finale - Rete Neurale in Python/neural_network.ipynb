{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reti Neurali con Python e Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe per una Rete Neurale\n",
    "Il processo di creazione di questa rete neurale è descritto passo passo in [questo articolo sul blog di ProfessionAI](http://blog.profession.ai/creare-una-rete-neurale-artificiale-da-zero/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "  \n",
    "  \n",
    "  def __init__(self, hidden_layer_size=100):\n",
    "    \n",
    "    self.hidden_layer_size=hidden_layer_size\n",
    "    \n",
    "    \n",
    "  def _init_weights(self, input_size, hidden_size):\n",
    "    \n",
    "    self._W1 = np.random.randn(input_size, hidden_size)\n",
    "    self._b1 = np.zeros(hidden_size)\n",
    "    self._W2 = np.random.randn(hidden_size,1)\n",
    "    self._b2 = np.zeros(1)\n",
    "\n",
    "    \n",
    "  def _accuracy(self, y, y_pred):      \n",
    "    return np.sum(y==y_pred)/len(y)\n",
    "  \n",
    "  \n",
    "  def _log_loss(self, y_true, y_proba):\n",
    "    return -np.sum(np.multiply(y_true,np.log(y_proba))+np.multiply((1-y_true),np.log(1-y_proba)))/len(y_true)\n",
    "  \n",
    "  \n",
    "  def _relu(self, Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "  \n",
    "  def _sigmoid(self, Z):\n",
    "    return 1/(1+np.power(np.e,-Z))\n",
    "  \n",
    "  \n",
    "  def _relu_derivative(self, Z):\n",
    "    dZ = np.zeros(Z.shape)\n",
    "    dZ[Z>0] = 1\n",
    "    return dZ\n",
    "    \n",
    "               \n",
    "  def _forward_propagation(self, X):\n",
    "                     \n",
    "    Z1 = np.dot(X,self._W1)+self._b1\n",
    "\n",
    "    A1 = self._relu(Z1)\n",
    "    Z2 = np.dot(A1,self._W2)+self._b2\n",
    "    A2 = self._sigmoid(Z2)\n",
    "    \n",
    "    self._forward_cache = (Z1, A1, Z2, A2)\n",
    "\n",
    "    return A2.ravel()\n",
    "\n",
    "\n",
    "  def predict(self, X, return_proba=False):\n",
    "\n",
    "      proba = self._forward_propagation(X)\n",
    "\n",
    "      y = np.zeros(X.shape[0])\n",
    "      y[proba>=0.5]=1\n",
    "      y[proba<0.5]=0\n",
    "\n",
    "      if(return_proba):\n",
    "        return (y, proba)\n",
    "      else:\n",
    "        return proba\n",
    "                            \n",
    "      \n",
    "  def _back_propagation(self, X, y):\n",
    "  \n",
    "    Z1, A1, Z2, A2 = self._forward_cache\n",
    "                   \n",
    "    m = A1.shape[1]\n",
    "    \n",
    "    dZ2 = A2-y.reshape(-1,1)\n",
    "    dW2 = np.dot(A1.T, dZ2)/m\n",
    "    db2 = np.sum(dZ2, axis=0)/m\n",
    "\n",
    "    dZ1 = np.dot(dZ2, self._W2.T)*self._relu_derivative(Z1)\n",
    "    dW1 = np.dot(X.T, dZ1)/m\n",
    "    db1 = np.sum(dZ1, axis=0)/m\n",
    "    \n",
    "    return dW1, db1, dW2, db2\n",
    "           \n",
    "               \n",
    "  def fit(self, X, y, epochs=200, lr=0.01):\n",
    "     \n",
    "    self._init_weights(X.shape[1], self.hidden_layer_size)\n",
    "      \n",
    "    for _ in range(epochs):\n",
    "      Y = self._forward_propagation(X)\n",
    "      dW1, db1, dW2, db2 = self._back_propagation(X, y)\n",
    "      self._W1-=lr*dW1\n",
    "      self._b1-=lr*db1\n",
    "      self._W2-=lr*dW2\n",
    "      self._b2-=lr*db2\n",
    "               \n",
    "\n",
    "  def evaluate(self, X, y):\n",
    "    y_pred, proba = self.predict(X, return_proba=True)\n",
    "    accuracy = self._accuracy(y, y_pred)\n",
    "    log_loss = self._log_loss(y, proba)\n",
    "    return (accuracy, log_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testiamo la Rete Neurale\n",
    "Per testare la nostra Rete Neurale utilizzeremo il Boston Breast Cancer Dataset, un dataset di tumori al seno etichettati come positivi o negativi.\n",
    "Importiamo il dataset direttamente dalla Repository Github dei Tutorial di ProfessionAI, per farlo possiamo utilizzare Pandas, una popolare libreria Python per l’analisi dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CSV_URL = \"https://raw.githubusercontent.com/ProfAI/tutorials/master/Come%20Creare%20una%20Rete%20Neurale%20da%20Zero/breast_cancer.csv\"\n",
    "\n",
    "breast_cancer = pd.read_csv(CSV_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il risultato sarà un DataFrame, una struttura dati che Pandas usa per rappresentare dati tabulari, possiamo avere una preview del suo contenuto usando il metodo .head().<br>\n",
    "Il nostro dataset contiene in totale 563 righe (e quindi esempi) e 31 colonne, cioè 30 features e un target, che è la colonna “malignant”.<br>\n",
    "Estraiamo features e target in array numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = breast_cancer.drop(\"malignant\", axis=1).values\n",
    "y = breast_cancer[\"malignant\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora dobbiamo dividere ogni array in due array distinti, uno per l’addestramento e uno per il test. Questa divisione serve per poter verificare le reali capacità predittive del modello, testandolo su dati che non ha già visto durante la fase di addestramento.\n",
    "Creiamo una funzione train_test_split per eseguire questa divisione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size=0.3, random_state=None):\n",
    "\n",
    "  if(random_state!=None):\n",
    "    np.random.seed(random_state)\n",
    "  \n",
    "  n = X.shape[0]\n",
    "\n",
    "  test_indices = np.random.choice(n, int(n*test_size), replace=False) # selezioniamo gli indici degli esempi per il test set\n",
    "  \n",
    "  # estraiamo gli esempi del test set\n",
    "  # in base agli indici\n",
    "  \n",
    "  X_test = X[test_indices]\n",
    "  y_test = y[test_indices]\n",
    "  \n",
    "  # creiamo il train set\n",
    "  # rimuovendo gli esempi del test set\n",
    "  # in base agli indici\n",
    "  \n",
    "  X_train = np.delete(X, test_indices, axis=0)\n",
    "  y_train = np.delete(y, test_indices, axis=0)\n",
    "\n",
    "  return (X_train, X_test, y_train, y_test )\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo assegnato il 30% degli esempi del dataset al set di test, quindi abbiamo 395 esempi per l’addestramento e 168 per il test, sono un po’ pochi per l’addestramento di una rete neurale, ma trattandosi di un modello con un solo strato nascosto possono andare bene.\n",
    "E’ buona norma portare le features in un range di valori comune, questo può velocizzare anche di tanto la fase di addestramento.\n",
    "Utilizziamo la normalizzazione, che si esegue sottraendo il valore minore e dividendo per la differenza tra il valore maggiore e il valore minore:\n",
    "\n",
    "$$ X_{norm} = \\frac{X-X_{min}}{X_{max}-X_{min}} $$\n",
    "\n",
    "Ricorda che dobbiamo sempre applicare le stesse trasformazioni ai dati di addestramento, a quelli di test, e in generale a tutti quelli che daremo in pasto alla nostra rete neurale, quindi calcoliamo massimo e minimo sul set di addestramento e usiamo questi valori per la normalizzazione di entrambi gli array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_max = X_train.max(axis=0)\n",
    "X_min = X_train.min(axis=0)\n",
    "\n",
    "X_train = (X_train - X_min)/(X_max-X_min)\n",
    "X_test = (X_test - X_min)/(X_max-X_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfetto ! Adesso creiamo la nostra rete con 10 nodi sullo strato nascosto, addestriamola sul set di addestramento per 500 epoche e valutiamola sul set di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9464285714285714, 0.210132727184693)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.fit(X_train, y_train, epochs=500, lr=0.01)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dato che i pesi vengono inizializzati a valori casuali il risultato può lievemente variare tra diverse esecuzioni della rete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La Rete Neurale funziona. E ora ?\n",
    "Mettiamo caso di ricevere i risultati di 6 nuovi esami radiografici, le features estratte da questi ci vengono consegnate all’interno di un file csv, carichiamolo con pandas, estraiamolo le features e normalizziamole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams_df = pd.read_csv(\"https://raw.githubusercontent.com/ProfAI/tutorials/master/Come%20Creare%20una%20Rete%20Neurale%20da%20Zero/exam%20results.csv\")\n",
    "\n",
    "X_new = exams_df.values\n",
    "X_new = (X_new - X_min)/(X_max-X_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora utilizziamo il metodo predict per classificare i risultati di tali esami, in modo da identificare eventuali tumori maligni, ottenendo anche la probabilità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_proba = model.predict(X_new, return_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stampiamo il risultato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risultato 1 = benigno (0.0000)\n",
      "Risultato 2 = maligno (0.9984)\n",
      "Risultato 3 = maligno (0.9959)\n",
      "Risultato 4 = benigno (0.0043)\n",
      "Risultato 5 = benigno (0.4778)\n",
      "Risultato 6 = benigno (0.0238)\n"
     ]
    }
   ],
   "source": [
    "classes = [\"benigno\", \"maligno\"]\n",
    "\n",
    "for i, (pred, proba) in enumerate(zip(y_pred, y_proba)):\n",
    "  print(\"Risultato %d = %s (%.4f)\" % (i+1, classes[int(pred)], proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando la probabilità associata non è alta andrebbero eseguiti ulteriori esami di verifica, specialmente nel caso di un tumore classificato come benigno, dato che classificare erroneamente un tumore maligno come benigno è molto più grave che classificare un tumore benigno come maligno.\n",
    "Come abbiamo visto in questo tutorial, in questi casi è opportuno utilizzare anche la matrice di confusione come metrica per valutare il modello."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
